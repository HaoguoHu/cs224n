{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.0\n",
      "tensor([[-7.5053e+25,  8.8282e-43, -7.5053e+25],\n",
      "        [ 8.8282e-43, -7.5053e+25,  8.8282e-43],\n",
      "        [-7.5053e+25,  8.8282e-43, -7.5053e+25],\n",
      "        [ 8.8282e-43, -7.5053e+25,  8.8282e-43],\n",
      "        [-7.5053e+25,  8.8282e-43, -7.5053e+25]])\n",
      "tensor([[-2147483648,           0, -2147483648],\n",
      "        [          0, -2147483648,           0],\n",
      "        [-2147483648,           0, -2147483648],\n",
      "        [          0, -2147483648,           0],\n",
      "        [-2147483648,           0, -2147483648]], dtype=torch.int32)\n",
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]], dtype=torch.int16)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "print(torch.__version__)\n",
    "\n",
    "x = torch.empty(5, 3)\n",
    "print(x)\n",
    "print(x.int())\n",
    "x = torch.zeros(5, 3, dtype=torch.short)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6041])\n",
      "0.6041225790977478\n",
      "tensor([1.6041], device='cuda:0')\n",
      "tensor([1.6041], dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.device"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(1)\n",
    "print(x)\n",
    "print(x.item())\n",
    "\n",
    "# let us run this cell only if CUDA is available\n",
    "# We will use ``torch.device`` objects to move tensors in and out of GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # a CUDA device object\n",
    "    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n",
    "    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\", torch.double))       # ``.to`` can also change dtype together!\n",
    "else:\n",
    "    print(\"No cuda\")\n",
    "\n",
    "torch.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUTOGRAD: AUTOMATIC DIFFERENTIATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n",
      "tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward0>)\n",
      "tensor([[27., 27.],\n",
      "        [27., 27.]], grad_fn=<MulBackward0>) tensor(108., grad_fn=<SumBackward0>)\n",
      "tensor([[18., 18.],\n",
      "        [18., 18.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "print(x)\n",
    "y = x + 2\n",
    "print(y)\n",
    "z = y * y * 3\n",
    "out = z.sum()\n",
    "\n",
    "print(z, out)\n",
    "out.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1526,  0.0538, -0.6229], requires_grad=True)\n",
      "tensor([  312.6021,   110.1364, -1275.7661], grad_fn=<MulBackward0>)\n",
      "tensor([2048., 2048., 2048.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, requires_grad=True)\n",
    "print(x)\n",
    "y = x * 2\n",
    "while y.data.norm() < 1000:\n",
    "    y = y * 2\n",
    "\n",
    "y.sum().backward()\n",
    "print(y)\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEURAL NETWORKS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLASS: Conv2d\n",
    "torch.nn.Conv2d (in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros')\n",
    "\n",
    "##### Parameters\n",
    "in_channels (int) – Number of channels in the input image\n",
    "\n",
    "out_channels (int) – Number of channels produced by the convolution\n",
    "\n",
    "kernel_size (int or tuple) – Size of the convolving kernel\n",
    "\n",
    "stride (int or tuple, optional) – Stride of the convolution. Default: 1\n",
    "\n",
    "padding (int or tuple, optional) – Zero-padding added to both sides of the input. Default: 0\n",
    "\n",
    "padding_mode (string, optional) – zeros\n",
    "\n",
    "dilation (int or tuple, optional) – Spacing between kernel elements. Default: 1\n",
    "\n",
    "groups (int, optional) – Number of blocked connections from input channels to output channels. Default: 1\n",
    "\n",
    "bias (bool, optional) – If True, adds a learnable bias to the output. Default: True\n",
    "\n",
    "### CLASS: MaxPool2d\n",
    "torch.nn.MaxPool2d(kernel_size, stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=False)\n",
    "\n",
    "##### Parameters\n",
    "kernel_size – the size of the window to take a max over\n",
    "\n",
    "stride – the stride of the window. Default value is kernel_size\n",
    "\n",
    "padding – implicit zero padding to be added on both sides\n",
    "\n",
    "dilation – a parameter that controls the stride of elements in the window\n",
    "\n",
    "return_indices – if True, will return the max indices along with the outputs. Useful for torch.nn.MaxUnpool2d later\n",
    "\n",
    "ceil_mode – when True, will use ceil instead of floor to compute the output shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next cell explained\n",
    "#### conv output\n",
    "output=(Width - filter+2*padding)/stride + 1 = width-filter+1 if stride==1 and padding==0\n",
    "\n",
    "#### max_pool  output\n",
    "output=(Width - dilation*(filter-1) + 2*padding -1 )/stride + 1 =(width-filter)/stride+1 if  dilation==1 and padding==0\n",
    "\n",
    "#### The filter shifts is the stride\n",
    "###### https://pytorch.org/docs/stable/nn.html#maxpool2d\n",
    "\n",
    "- (32x32x1)  -> conv1 -> (32-3+1)     -> (30 x 30 x  6)       !conv filter=3  \n",
    "- (30x30x6)  -> max1  -> (30-2)/2 + 1 -> (15 x 15 x  6)   !max_pool filter=2, stride=2\n",
    "- (15x15x6)  -> conv2 -> (15-3+1)     -> (13 x 13 x 16)\n",
    "- (13x13x16) -> max2  -> (13-2)/2 +1) -> ( 6 x 6  x 16)    !ceil_mode –false, use floor to compute the output shape\n",
    "- (6x6x16)= 576 -> Linear -> 120\n",
    "- 120 -> Linear -> 84\n",
    "-  84 -> Linear -> output_dim 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out1= torch.Size([1, 3, 30, 30])\n",
      "out2= torch.Size([1, 3, 15, 15])\n",
      "out3= torch.Size([1, 3, 13, 13])\n",
      "out4= torch.Size([1, 3, 6, 6])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "m = nn.MaxPool2d(2, stride=2)\n",
    "c = nn.Conv2d(3,3,3)\n",
    "input = torch.randn(1, 3, 32, 32)\n",
    "o1  = c(input)\n",
    "print('out1=',o1.size())\n",
    "o2  = m(o1)\n",
    "print('out2=',o2.size())\n",
    "o3  = c(o2)\n",
    "print('out3=',o3.size())\n",
    "o4  = m(o3)\n",
    "print('out4=',o4.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.0532,  1.9126],\n",
      "        [ 0.0570,  1.0065],\n",
      "        [ 0.6955, -0.3806],\n",
      "        [-0.3456,  1.4938]])\n",
      "tensor([[0.0000, 1.9126],\n",
      "        [0.0570, 1.0065],\n",
      "        [0.6955, 0.0000],\n",
      "        [0.0000, 1.4938]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = nn.ReLU()\n",
    "#m = nn.LeakyReLU(0.1)\n",
    "input = torch.randn(4,2)\n",
    "print(input)\n",
    "output = m(input)\n",
    "print(output)\n",
    "output.size()[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=576, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "0 torch.Size([6, 1, 3, 3])\n",
      "1 torch.Size([6])\n",
      "2 torch.Size([16, 6, 3, 3])\n",
      "3 torch.Size([16])\n",
      "4 torch.Size([120, 576])\n",
      "5 torch.Size([120])\n",
      "6 torch.Size([84, 120])\n",
      "7 torch.Size([84])\n",
      "8 torch.Size([10, 84])\n",
      "9 torch.Size([10])\n",
      "out= tensor([[-0.0205,  0.0699, -0.0033,  0.0544,  0.1031,  0.0382,  0.1040,  0.0050,\n",
      "          0.0070,  0.1053]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.9842,  0.5793,  0.3579,  0.6251,  0.2562, -0.4711,  2.3612,  0.1180,\n",
      "         -0.8601,  0.0359]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 3x3 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)         #in 1, out  6, kernel 3x3\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)        #in 6, out 16, kernel 3x3\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 6 * 6, 120)   # 6*6 from image dimension\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)\n",
    "\n",
    "params = list(net.parameters())\n",
    "#print(len(params))\n",
    "#print(params[0].size())  # conv1's .weight\n",
    "\n",
    "for i in range(len(params)):\n",
    "    print(i,params[i].size())\n",
    "#print(params[0])\n",
    "\n",
    "input = torch.randn(1, 1, 32, 32) # 1 batch size, 1 input chanel , hight 32 , width 32\n",
    "\n",
    "out = net(input)\n",
    "print('out=',out)\n",
    "\n",
    "net.zero_grad()\n",
    "a = torch.randn(1,10)\n",
    "print(a)\n",
    "out.backward(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.5181, grad_fn=<MseLossBackward>)\n",
      "<MseLossBackward object at 0x00000276F625BAC8>\n",
      "<AddmmBackward object at 0x00000276818CD390>\n",
      "<AccumulateGrad object at 0x00000276F625BAC8>\n"
     ]
    }
   ],
   "source": [
    "output = net(input)\n",
    "target = torch.randn(10)  # a dummy target, for example\n",
    "#print(target.shape)\n",
    "target = target.view(1, -1)  # make it the same shape as output\n",
    "#print(target.shape)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "loss = criterion(output, target)\n",
    "print(loss)\n",
    "print(loss.grad_fn)  # MSELoss\n",
    "print(loss.grad_fn.next_functions[0][0])  # Linear\n",
    "print(loss.grad_fn.next_functions[0][0].next_functions[0][0])  # ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.bias.grad before backward\n",
      "tensor([0., 0., 0., 0., 0., 0.])\n",
      "conv1.bias.grad after backward\n",
      "tensor([-0.0133, -0.0145,  0.0070,  0.0133,  0.0116,  0.0298])\n"
     ]
    }
   ],
   "source": [
    "net.zero_grad()     # zeroes the gradient buffers of all parameters\n",
    "\n",
    "print('conv1.bias.grad before backward')\n",
    "print(net.conv1.bias.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('conv1.bias.grad after backward')\n",
    "print(net.conv1.bias.grad)\n",
    "\n",
    "learning_rate = 0.01\n",
    "for f in net.parameters():\n",
    "    f.data.sub_(f.grad.data * learning_rate)\n",
    "    \n",
    "   \n",
    "import torch.optim as optim\n",
    "\n",
    "# create your optimizer\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "# in your training loop:\n",
    "optimizer.zero_grad()   # zero the gradient buffers\n",
    "output = net(input)\n",
    "loss = criterion(output, target)\n",
    "loss.backward()\n",
    "optimizer.step()    # Does the update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
